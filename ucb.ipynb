{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper confidence bound Algorithm (Multi Armed Bandit)\n",
    "\n",
    "(Naveen Mysore, navimn1991@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Multi armed bandit algorithms are a class of powerful algorithms that run the modern world. They are used every where from running clinical trails with RCT, Massive AB Testing to recommeding movies on Netflix. The problem is still open for an optimal or near optimal solution and studies are still being conducted to find a scalable solution [reference](https://www.nature.com/articles/s41598-021-83726-8). On the other hand some empirical studies done by evolutionary biologists seem to show that plants and slime molds can solve this problem in a tractable time [reference](https://royalsocietypublishing.org/doi/full/10.1098/rsif.2016.0030) which questions the fundamentals of intellgence theory. These algorithms are so powerful that, studies are now being conducted in political sciences to see how are they affecting modern democracy [reference](https://www.tandfonline.com/doi/abs/10.1080/08838151.2020.1757365) and polarization of society. If you use any of the internet products like Netflix, TikTok, E commerce platforms or any social media platform then you might have noticed that they recommend products or media contents that so well tuned for your tastes [reference](https://www.youtube.com/watch?v=kY-BCNHd_dM&t=589s&ab_channel=DataCouncil). These systems have modelled your behaviour so well that they do a great job at grabbing your attention. In this article, I will conduct an empirical study showing how these algorithms work so that we can study their impacts on real world. We will first define the problem and explore solutions like epsilon greedy algorithms and upper confidence bound algorithms and lay ground work for contextual bandit algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[Multi armed bandit algorithms](https://en.wikipedia.org/wiki/Multi-armed_bandit) derive their origins from probablity theory and machine learning. The core of the problem is the exploration - exploitation dilemma that an autonomous agent suffers. An autonomous agent is something that is capable of making it's own decision based on perceived information. For example, You and I are autonomous agents since we receive information from our environment and take actions based on some decisions. At every instance of time an autonomous agent has to make a decision whether to explore something new or to exploit something which is familiar to it. Based on the decision chosen by the agent, the environment rewards the agent with some positive or negative feedback. The problem is often explained using an analogy of a casino slot machine. Typically a casino slot machine has on arm lever, now imagine a slot machine with $k$ arms or lever. You are faced repeatedly with a choice among $k$ different actions or options. After each choice you receive a numerical reward chosen from a stationary probablity distribution that depends on the action you selected. The objective here is to maximize the expected total reward over some time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon Greedy and UCB\n",
    "\n",
    "Epsilon-Greedy is a simple method to balance exploration and exploitation by choosing between exploration and exploitation randomly. The epsilon-greedy, where epsilon refers to the probability of choosing to explore, exploits most of the time with a small chance of exploring. Unlike episolon greedy, rather than performing exploration by simply selecting an arbitrary action, chosen with a probability that remains constant, the UCB algorithm changes its exploration-exploitation balance as it gathers more knowledge of the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup\n",
    "\n",
    "The goal of this experiment is to compare multi arm bandit problem with epsilon $\\epsilon$ greedy approach and upper confidence bound algorithm. In this experiment we will setup $k=10$ arm bandit and compare four epsilon approaches (0.0, 0.01, 0.1, 0.5) followed by upper confidence bound method. We will be running lots of iterations and episodes. Computing averages for these rewards are both space and computationally expensive and hence we will be using running averages. This implies we just need to store two variables in memory ( previous mean and current reward ). Here is the derivation.\n",
    "\n",
    "Let $m_n$ be mean or average value of rewards at $n^{th}$ time step. Let $n$ be the total number of iterations. Let $R_i$ be reward at $i^{th}$ time step.\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{equation*}\n",
    "m_n = \\frac{\\sum_{i=1}^n R_i}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "m_n = \\frac{(\\sum_{i=1}^{n-1}R_i)+R_n}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "m_n = \\frac{Rn}{n}+\\frac{\\sum_{i=1}^{n-1}R_{n-1}}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "The sum of $n-1$ rewards $\\sum_{i=1}^{n-1}R_{n-1}$ can also be written as $m_{n-1}$*${n-1}$. Using this the previous equation can be written as\n",
    "\n",
    "\\begin{equation*}\n",
    "m_n = \\frac{Rn}{n} + \\frac{(n-1)m_{n-1}}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "Rearranging terms we get\n",
    "\\begin{equation*}\n",
    "m_n = m_{n-1}+\\frac{R_{n}-m_{n-1}}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "Which means, just by keep track of current reward $R_{i}$ and running mean $m_{n-1}$ we can update the new mean $m_{n}$ by above equation.\n",
    "\n",
    "\\begin{equation*}\n",
    "m_n  \\Leftarrow m_{n-1}+\\frac{R_{n}-m_{n-1}}{n}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programatically we can express this as function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_average = lambda m_n_1, r_i, n: m_n_1 + ((r_i - m_n_1) / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import all the packages we will be needing for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment reward setup\n",
    "\n",
    "We can imagine a system with $k$ arms and for each arm the machine gives us a numerical reward from a sample distribution of mean $mu$ and standard deviation $sd$. We can the model this distrubtion with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardDistribution:\n",
    "    def __init__(self, k=10):\n",
    "        self.k = k\n",
    "        self.mu = 0\n",
    "        self.sigma = 1\n",
    "        self.q_star_mu = np.random.normal(self.mu, self.sigma, k)\n",
    "        self.q_star_sd = np.ones(k)\n",
    "\n",
    "    def get_reward(self, action):\n",
    "        Rt = np.random.normal(self.q_star_mu[action], self.q_star_sd[action], 1)\n",
    "        return Rt\n",
    "    \n",
    "    def plot(self):\n",
    "        # create a data frame to plot the distribution\n",
    "        df = {}\n",
    "        sample_size = 1000\n",
    "        for action in range(self.k):\n",
    "            mu = self.q_star_mu[action]\n",
    "            sd = self.q_star_sd[action]\n",
    "            df[f'action_{action}'] = np.random.normal(mu, sd, sample_size)\n",
    "        df = pd.DataFrame(data=df)\n",
    "        sns.boxplot(data=df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's model a system with 10 arms and visulize its reward distribution. For each action (pulling a slot arm) the system samples rewards from a distribution of (0,1) and awards it to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rd = RewardDistribution(k=10)\n",
    "rd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course in reality you would not know this distribution. If you knew it your probabaly would have been a millionaire by now. Even though we wouldn't know this universe encoded distribution we can use the stategic approach of epsilon greedy to model this distribution.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q values\n",
    "\n",
    "In the literature we model these average estimates as <b>$Q$</b> values. Using a similar defination as above let <b>$R_i$</b> now denote reward received after the <b>$i^ith$</b> iteration for a given action. Let <b>$Q_n$</b> denote the estimate of its action value after it has been selected <b>$n-1$</b> times then\n",
    "\n",
    "\\begin{equation*}\n",
    "Q_n = \\frac{R_1+R_2+R_3+....+R_n-1}{n-1}\n",
    "\\end{equation*}\n",
    "\n",
    "From the derivation made using running averages we can say\n",
    "\n",
    "\\begin{equation*}\n",
    "Q_{n+1} = Q_n + \\frac{1}{n}*(R_n-Q_n)\n",
    "\\end{equation*}\n",
    "\n",
    "This can be informally viewed as this\n",
    "\n",
    "<b>New Estimate</b> $\\leftarrow$ <b>Old Estimate</b> + <b>Step Size</b> (<b>Target</b> - <b>Old Estimate</b>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon bandit\n",
    "\n",
    "In this model we will setup $k=10$ arm bandit for the system and compare four epsilon approaches (0.0, 0.01, 0.1, 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsBandit:\n",
    "    def __init__(self, rd, k, eps, iterations):\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "        self.total_avg_reward = 0.0\n",
    "        self.qa = np.zeros(self.k)\n",
    "        self.ac = np.zeros(self.k)\n",
    "        self.iterations = iterations\n",
    "        self.rd = rd\n",
    "\n",
    "    def sample_an_action(self):\n",
    "\n",
    "        def greedy_action():\n",
    "            # pick action corresponding to high qa\n",
    "            return np.argmax(self.qa)\n",
    "\n",
    "        def random_action():\n",
    "            # pick random action from k selections\n",
    "            return np.random.choice(self.k)\n",
    "\n",
    "        if self.eps == 0:\n",
    "            # always greedy choice\n",
    "            return greedy_action()\n",
    "        else:\n",
    "            p = np.random.rand()\n",
    "            # high epsilon means more weight to random actions\n",
    "            if p < self.eps:\n",
    "                return random_action()\n",
    "            else:\n",
    "                return greedy_action()\n",
    "\n",
    "    def execute_an_action(self, action):\n",
    "        sampled_rewards = self.rd.get_reward(action=action)\n",
    "        self.ac[action] += 1\n",
    "        return sampled_rewards\n",
    "\n",
    "    def log(self, t, action, r_t):\n",
    "        print(f'==== step {t} ====')\n",
    "        print(f'Sampled a reward {r_t} for action A_{action}')\n",
    "        print(f'Tr {self.total_avg_reward}')\n",
    "        print(f'qa {self.qa}')\n",
    "        print(f'ac {self.ac}')\n",
    "        print('\\n')\n",
    "\n",
    "    def get_total_average_rewards(self):\n",
    "        return self.total_avg_reward\n",
    "    \n",
    "    def get_action_dist(self):\n",
    "        return self.ac\n",
    "    \n",
    "    def run(self):\n",
    "        avg_reward = [0.0]\n",
    "        for t in range(1, self.iterations):\n",
    "            action = self.sample_an_action()\n",
    "            r_t = self.execute_an_action(action)\n",
    "            self.total_avg_reward = running_average(m_n_1=self.total_avg_reward, r_i=r_t, n=t)\n",
    "            self.qa[action] = running_average(m_n_1=self.qa[action], r_i=r_t, n=self.ac[action])\n",
    "            avg_reward.append(float(self.total_avg_reward))\n",
    "        return avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epsilon 0.0 means we always take greedy actions, actions which have maximum rewards in the past. epsilon 0.5 means, 50% of the time we can actions which have maximum rewards in the past and 50% time we will be taking random actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(k=5, iterations=1000):\n",
    "    rd = RewardDistribution(k=k)\n",
    "    #rd.plot()\n",
    "    data = {}\n",
    "    \n",
    "    fmt = lambda i, eps, cnt: {'action': f\"action_{i}\", 'count': cnt, 'epsilon': f\"eps_{eps}\"}\n",
    "    \n",
    "    eps_0 = EpsBandit(rd=rd, k=k, eps=0.0, iterations=iterations)\n",
    "    data['eps_0'] = eps_0.run()\n",
    "\n",
    "    eps_0_0_1 = EpsBandit(rd=rd, k=k, eps=0.01, iterations=iterations)\n",
    "    data['eps_0_0_1'] = eps_0_0_1.run()\n",
    "\n",
    "    eps_0_1 = EpsBandit(rd=rd, k=k, eps=0.1, iterations=iterations)\n",
    "    data['eps_0_1'] = eps_0_1.run()\n",
    "    \n",
    "    eps_0_5 = EpsBandit(rd=rd, k=k, eps=0.5, iterations=iterations)\n",
    "    data['eps_0_5'] = eps_0_5.run()\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now lets run this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just ran this experiment for a time step of 1000 and we the collected the running average rewards for different epsilon. As we repeat these experiments our <b>Q</b> values will converge to <b>Q*</b> values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running episodes\n",
    "\n",
    "If you notice we sampled reward distribution one time <b>RewardDistribution</b> and we reused it for different epsilon experiment. We need to repeat this experiment many times with different reward distribution for our values to converge to optimal values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episodes(episodes=1000):\n",
    "    result = dict()\n",
    "    iterations = 1000\n",
    "    result['eps_0'] = np.zeros(iterations)\n",
    "    result['eps_0_0_1'] = np.zeros(iterations)\n",
    "    result['eps_0_1'] = np.zeros(iterations)\n",
    "    result['eps_0_5'] = np.zeros(iterations)\n",
    "    for episode in range(1, episodes):\n",
    "        df = run_experiment(k=10, iterations=iterations)\n",
    "        result['eps_0'] = running_average(m_n_1=result['eps_0'], r_i=np.asarray(df['eps_0']), n=episode)\n",
    "        result['eps_0_0_1'] = running_average(m_n_1=result['eps_0_0_1'], r_i=np.asarray(df['eps_0_0_1']), n=episode)\n",
    "        result['eps_0_1'] = running_average(m_n_1=result['eps_0_1'], r_i=np.asarray(df['eps_0_1']), n=episode)\n",
    "        result['eps_0_5'] = running_average(m_n_1=result['eps_0_5'], r_i=np.asarray(df['eps_0_5']), n=episode)\n",
    "        _df = pd.DataFrame(result)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data we need, we shall format it and prepare for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_plotting(_df):\n",
    "    entries = []\n",
    "    for time_step in range(0, 1000):\n",
    "        entries.append({'time_step': time_step, 'epsilon': 'eps_0', 'average_reward': _df['eps_0'][time_step]})\n",
    "        entries.append({'time_step': time_step, 'epsilon': 'eps_0_0_1', 'average_reward': _df['eps_0_0_1'][time_step]})\n",
    "        entries.append({'time_step': time_step, 'epsilon': 'eps_0_1', 'average_reward': _df['eps_0_1'][time_step]})\n",
    "        entries.append({'time_step': time_step, 'epsilon': 'eps_0_5', 'average_reward': _df['eps_0_5'][time_step]})\n",
    "    dframe = pd.DataFrame(entries)\n",
    "    return dframe\n",
    "    \n",
    "_df = run_episodes(episodes=100)\n",
    "dframe = prepare_data_for_plotting(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fab97c56fd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=dframe, x='time_step', y='average_reward', hue='epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimistic Initial Values in non stationary environments\n",
    "\n",
    "The methods discussed so far are dependent to some extent on the initial Q values, ie, $Q_1(a)$. In other words these methods are biases with initial values of $Q$. The bias will disappear when all actions are samples infinite time by the law of large numbers. On the other hand in the methods discusses so far we assumed that the enviornment is fixed with a sationary reward distribution. However we know that in real world reward distibution keep changing. So model this problem we need the agent must be encourage to explore more based on the enviorment dynamics. \n",
    "\n",
    "\\begin{equation*}\n",
    "Q_{n+1} = Q_n + \\alpha*(R_n-Q_n)\n",
    "\\end{equation*}\n",
    "\n",
    "Derivation and implemenation details are beyond the scope of this article or may be I will find some time to implmement them in future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper confidence bound\n",
    "\n",
    "In this model we will use same setup $k=10$ arm bandit for the slot machine and compare four epsilon approaches (0.0, 0.01, 0.1) with upper confidence bound. e-greedy action selection forces the non-greedy actions to be tried, but indiscriminately, with no preferance for those of near greedy. We need to taken into account how close estimates are for other actions too. \n",
    "\n",
    "\\begin{equation*}\n",
    "A_t = argmax(Q_t(a)+c*\\sqrt{\\frac{ln(t)}{N_t(a)}})\n",
    "\\end{equation*}\n",
    "\n",
    "$ln(t)$ denotes the natural logarithm of time steps and $N_t(a)$ represents number of times an action was chosen. In the above equation the square root term measures the uncertainity or variance in the estimates of action values. And $c$ represents the confidence in those estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBandit:\n",
    "    def __init__(self, rd, k, iterations):\n",
    "        self.k = k\n",
    "        self.total_avg_reward = 0.0\n",
    "        self.qa = np.zeros(self.k)\n",
    "        self.ac = np.ones(self.k)\n",
    "        self.iterations = iterations\n",
    "        self.rd = rd\n",
    "        self.c = 2\n",
    "    \n",
    "    def sample_an_action(self):\n",
    "        uncertainity = np.log(self.iterations)/self.ac\n",
    "        uc = self.c * np.sqrt(uncertainity)\n",
    "        return np.argmax(self.qa+uc)\n",
    "\n",
    "    def execute_an_action(self, action):\n",
    "        sampled_rewards = self.rd.get_reward(action=action)\n",
    "        self.ac[action] += 1\n",
    "        return sampled_rewards\n",
    "\n",
    "    def log(self, t, action, r_t):\n",
    "        print(f'==== step {t} ====')\n",
    "        print(f'Sampled a reward {r_t} for action A_{action}')\n",
    "        print(f'Tr {self.total_avg_reward}')\n",
    "        print(f'qa {self.qa}')\n",
    "        print(f'ac {self.ac}')\n",
    "        print('\\n')\n",
    "\n",
    "    def get_total_average_rewards(self):\n",
    "        return self.total_avg_reward\n",
    "    \n",
    "    def get_action_dist(self):\n",
    "        return self.ac\n",
    "    \n",
    "    def run(self):\n",
    "        avg_reward = [0.0]\n",
    "        for t in range(1, self.iterations):\n",
    "            action = self.sample_an_action()\n",
    "            r_t = self.execute_an_action(action)\n",
    "            self.total_avg_reward = running_average(m_n_1=self.total_avg_reward, r_i=r_t, n=t)\n",
    "            self.qa[action] = running_average(m_n_1=self.qa[action], r_i=r_t, n=self.ac[action])\n",
    "            avg_reward.append(float(self.total_avg_reward))\n",
    "            #self.log(t, action, r_t)\n",
    "        return avg_reward\n",
    "                         \n",
    "def run_experiment(k=5, iterations=1000):\n",
    "    rd = RewardDistribution(k=k)\n",
    "    #rd.plot()\n",
    "    data = {}\n",
    "    \n",
    "    fmt = lambda i, eps, cnt: {'action': f\"action_{i}\", 'count': cnt, 'epsilon': f\"eps_{eps}\"}\n",
    "    \n",
    "    eps_0 = EpsBandit(rd=rd, k=k, eps=0.0, iterations=iterations)\n",
    "    data['eps_0'] = eps_0.run()\n",
    "\n",
    "    eps_0_0_1 = EpsBandit(rd=rd, k=k, eps=0.01, iterations=iterations)\n",
    "    data['eps_0_0_1'] = eps_0_0_1.run()\n",
    "\n",
    "    eps_0_1 = EpsBandit(rd=rd, k=k, eps=0.1, iterations=iterations)\n",
    "    data['eps_0_1'] = eps_0_1.run()\n",
    "    \n",
    "    uc_bandit = UCBandit(rd=rd, k=k, iterations=iterations)\n",
    "    data['uc_bandit'] = uc_bandit.run()\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = run_experiment()\n",
    "\n",
    "def run_episodes(episodes=1000):\n",
    "    result = dict()\n",
    "    iterations = 1000\n",
    "    result['eps_0'] = np.zeros(iterations)\n",
    "    result['eps_0_0_1'] = np.zeros(iterations)\n",
    "    result['eps_0_1'] = np.zeros(iterations)\n",
    "    result['uc_bandit'] = np.zeros(iterations)\n",
    "    for episode in range(1, episodes):\n",
    "        df = run_experiment(k=10, iterations=iterations)\n",
    "        result['eps_0'] = running_average(m_n_1=result['eps_0'], r_i=np.asarray(df['eps_0']), n=episode)\n",
    "        result['eps_0_0_1'] = running_average(m_n_1=result['eps_0_0_1'], r_i=np.asarray(df['eps_0_0_1']), n=episode)\n",
    "        result['eps_0_1'] = running_average(m_n_1=result['eps_0_1'], r_i=np.asarray(df['eps_0_1']), n=episode)\n",
    "        result['uc_bandit'] = running_average(m_n_1=result['uc_bandit'], r_i=np.asarray(df['uc_bandit']), n=episode)\n",
    "        _df = pd.DataFrame(result)\n",
    "    return _df\n",
    "\n",
    "def prepare_data_for_plotting(_df):\n",
    "    entries = []\n",
    "    for time_step in range(0, 1000):\n",
    "        entries.append({'time_step': time_step, 'algorithm': 'eps_0', 'average_reward': _df['eps_0'][time_step]})\n",
    "        entries.append({'time_step': time_step, 'algorithm': 'eps_0_0_1', 'average_reward': _df['eps_0_0_1'][time_step]})\n",
    "        entries.append({'time_step': time_step, 'algorithm': 'eps_0_1', 'average_reward': _df['eps_0_1'][time_step]})\n",
    "        entries.append({'time_step': time_step, 'algorithm': 'uc_bandit', 'average_reward': _df['uc_bandit'][time_step]})\n",
    "    dframe = pd.DataFrame(entries)\n",
    "    return dframe\n",
    "    \n",
    "_df = run_episodes(episodes=100)\n",
    "dframe = prepare_data_for_plotting(_df)\n",
    "\n",
    "sns.lineplot(data=dframe, x='time_step', y='average_reward', hue='algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associative Search (Contextual Bandits)\n",
    "\n",
    "Associated search involves both trial-and-error learning to search for the best actions and associations of these actions with the situations in which they are best. Associative search tasks are intermediate between the k-armed bandit and the reinforcement learning problem. The scope of study of these algorithms are beyond the scope of this article and I plan to cover them in upcoming articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In these article we defined the problem of explortion/explotiation and its applications in real world. We also demonstated that near greedy solutions are efficient in epsilon greedy settings. We also saw Upper confidence bound algorithms perform better than epsilon greedy algorithms but they are limited to stationary enviornments. We finally laid ground work to associative search or contextual bandits algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
